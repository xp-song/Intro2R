---
title: "Data Wrangling and Visualisation"
subtitle: "[Intro2R](https://github.com/xp-song/Intro2R) crash course: Session 2 of 2"
author: "author: xpsong"
date: "updated: `r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
    theme: paper
    code_folding: hide
---

---

In this lesson, we will be analysing the [Kaggle Machine Learning and Data Science Survey 2018](https://www.kaggle.com/kaggle/kaggle-survey-2018) dataset. The industry-wide survey presents the state of data science and machine learning. It was published in as raw a format as possible while ensuring the anonymity of respondents.  

The data comes in three different files:

1. **Multiple choice responses**, which we will later assign to variable `multi`.  

2. **Free-form responses** to open-ended questions, which we will later assign to variable `free`.
  - To protect the privacy of respondents, the rows have been randomized such that the responses do not necessarily come from the same survey-taker as those in the multiple choice responses.

3. **Survey schema** shows an overview of responses.  

<br>

**In this lesson, we will only be using the file containing the multiple choice responses.**

_**Credit:** Our analysis includes code adapted from R Notebooks published by the Kaggle users [Heads or Tails](https://www.kaggle.com/headsortails/what-we-do-in-the-kernels-a-kaggle-survey-story) and [Jose Berengueres](https://www.kaggle.com/harriken/storytelling-the-2018-kaggle-survey)._ 

---

# Preparation {.tabset .tabset-fade .tabset-pills}

## Load packages

- We delve deeper into the [tidyverse](https://www.tidyverse.org) in this lesson, which will require the installation of numerous other packages for data manipulation. 

- We also will use some packages that provide functions for specific analyses and visualisations (e.g. dealing with geospatial data, interactive visualisations, etc.)  

```{r load_packages, message = FALSE, warning = FALSE}
#general data manipulation
library(dplyr) # data manipulation
library(readr) # input/output
library(data.table) # data manipulation
library(tibble) # data wrangling
library(tidyr) # data wrangling
library(stringr) # string manipulation
library(forcats) # factor manipulation

#specific data manipulation
library(purrr) # string manipulation

#general visualisations
library(ggplot2) # visualisation 

#specific visualisation
library(highcharter) # visualisation
library(countrycode) # visualisation


#to knit HMTL document
library(knitr) 
library(kableExtra) 
```

---  

## Load data

Rather than importing our tabular data as _dataframes_, we will import them as _tibbles_. Tibbles are a modern take on dataframes; they keep the features that have stood the test of time, and drop the features that used to be convenient but are now frustrating. More info about tibbles are available [here](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html). 

```{r}
multi <- as_tibble(fread('../data/kaggle-survey-2018/multipleChoiceResponses.csv', skip = 1))

#The function 'fread' in the library(data.table) speeds up reading of data into R
#We skip the first line of the .csv file. The second line contains the actual question headers that become the temporary column names for our data.
```

---  

## Examine data

- Use `colnames()` to examine column names. 
  - They are super-long sentences with white spaces, so we need to wrap the entire colname with backticks (e.g. `` multi$`Duration (in seconds)` ``)
  - This is not very feasible/readable code
  - We'll abbreviate the colnames later on as we analyse each topic in the survey.

- Use `str()` to examine the data classes/structure.

<br>

---  

## Convert data type

The `as_tibble()` function imports text as _character_ format by default. We want to change the multiple choice answers to _factors_ using `mutate_if()`.

- Use the pipe operator `%>%` from `library(dplyr)` to manipulate data in stages 
  - It is a key operater often used in the `tidyverse`.
  - Rather than using nested brackets, the 'pipeline' is highly readable and follows a logical sequence.
```{r}
multi <- multi %>%
  mutate_if(is_character, as_factor)

#functions 'is_character' and 'as_factor' are from the library(purrr) and library(forcats), respectively
```

---  

# Survey results {.tabset .tabset-fade .tabset-pills}

Number of respondents: __*`r nrow(multi)`*__  


## Duration

Let's first abbreviate the colname `` `Duration (in seconds)` ``  to `duration` using `rename()`, and change the units from seconds to minutes using `mutate()`.
```{r}
multi <- multi %>%
  rename(duration = `Duration (in seconds)`) %>% #rename column
  mutate(duration = duration/60) #change to minutes (use new colname)
```


Next, we plot a histogram using the function `ggplot()` from `library(ggplot2)`, a very popular package used for data visualisation (see [cheatsheet](https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf)).  

Three basic steps (linked with the `+` sign):  
1. Provide _data_  
2. Assign your data _variables_ to _aesthetics_  
3. Assign the graphical _primitives_  
```{r fig.height=3.5, fig.cap="_Note: The dashed line denotes the median survey duration. The x-axis has been transformed to a logarithmic scale._"}
multi %>% #provide data
  ggplot(aes(duration)) + #assign variable 'duration' to aes()
  geom_histogram(bins = 50, fill = "grey") + #graphical primitive
  
  #customisation
  scale_x_log10(breaks = c(2, 5, 10, 20, 60, 720, 1440)) + #log() x-axis to address extreme values
  geom_vline(xintercept = median(multi$duration), linetype = 2) + #add line for median duration
  labs(x = "Duration (mins)", y = "Number of respondents") + #change axis labels
  ggtitle("Most respondents took 15-20 min to complete survey") #add figure title
```

- Some respondents finished the survey in < 2 mins! They may have rushed it or left it incomplete.
- Some respondents probably left the browser tab open for a loong time.

---  

## Spatial distribution

Here, we are interested in the column `` `In which country do you currently reside?` ``. We want a summary table with the count of respondents per country.

```{r}
ctry_n <- multi %>%
  rename(country = `In which country do you currently reside?`) %>%
  count(country) %>%
  filter(!(country %in% c("Other", "I do not wish to disclose my location"))) %>%
  mutate(iso3 = countrycode(country, origin = "country.name", destination = "iso3c"))
```

- Abbreviate the colname to `country`
- `count()` the number of of observations per `country`
- `filter()` to exclude (`!`) invalid country names (rows) specified `%in%` the vector
- `mutate()` table to add a new column `iso3`, where factor names in `country` are mapped to the country code using `countrycode()`
- Notice that we are not overwriting the variable `multi`, but creating a new variable `ctry_n`

```{r echo = FALSE}
kable(ctry_n, format = "html") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = T, position = "center") %>%
    scroll_box(height = "200px")
```

<br>

Next, we plot our summary table `ctry_n` as an interactive map using the package [highcharter](http://jkunst.com/highcharter). The map data comes from https://code.highcharts.com/mapdata/custom/world.js. More info [here](https://cran.rstudio.com/web/packages/highcharter/highcharter.pdf). 

```{r fig.height=6}
highchart() %>%
  hc_add_series_map(worldgeojson, #map data to add
                    ctry_n, #our data
                    value = 'n', #colname of interest in ctry_n
                    joinBy = 'iso3') %>% #both datasets have this colname (country code)
  
  #customisation
  hc_title(text = 'Geographical distribution of survey respondents') %>%
  hc_colorAxis(minColor = "#edf8b1", maxColor = "#2c7fb8") %>%
  hc_tooltip(useHTML = TRUE, headerFormat = "", pointFormat = "{point.country}: {point.n} respondents")
```

---

## 



---  

## Educational sources

```{r}
multi <- multi %>%
  rename(platform = "On which online platform have you spent the most amount of time? - Selected Choice") %>%
  mutate(platform = na_if(platform, ""))
```

, keep in mind that the “On which online platforms” question allowed for multiple answers. In terms of ML/DS training we only consider percentages > 0, since zero dominates almost every distribution (except for self-taught) and we want to focus on the difference between the small and large percentages.

```{r}
platform_lvl <- multi %>%
  filter(!is.na(platform)) %>%
  mutate(platform = as.character(platform)) %>%
  count(platform) %>%
  arrange(n) %>%
  .$platform

foo <- multi %>%
  group_by(platform) %>%
  summarise(most_often = n()) %>%
  mutate(platform = as.character(platform))

bar <- multi %>%
  select(starts_with("On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice")) %>%
  replace(.=="", NA) %>%
  gather(key = "foo", value = "platform") %>%
  mutate(platform = as.character(platform)) %>%
  group_by(platform) %>%
  summarise(occasionally = n())

p1 <- foo %>%
  filter(!is.na(platform)) %>%
  left_join(bar, by = "platform") %>%
  mutate(platform = fct_relevel(platform, platform_lvl)) %>%
  gather(most_often, occasionally, key = "type", value = "n") %>%
  ggplot(aes(platform, n, fill = type)) +
  geom_col(position = "dodge") +
  theme(legend.position = "top") +
  coord_flip() +
  labs(x = "", y = "Responses", fill = "Usage")  +
  ggtitle("Online learning platforms")
```









Write cleaned data without the index column (i.e. write.csv)


# Your turn!

```{r eval = FALSE}
diamonds <- data(diamonds, package = "ggplot2")

#Some analysis
http://statweb.stanford.edu/~jtaylo/courses/stats202/diamonds.html

```



```{r eval = FALSE}

#NAs
is.na()

#1
na.omit(datafilename): remove ALL rows with NAs #But may remove valuable info!

#2
- Check VARIABLES with high proportion of NA first using use apply(X, MARGIN, FUN, ...)+
apply(apply(CO2,2,is.na),2,sum): indicates how many NAs in EACH column (a NESTED apply function)

#3
nonNAvalues <- complete.cases(dataframename): create a logical vector
dataframename[nonNAvalues,]: Subset & see only non-NA values


CO2[CO2$Type == "Mississippi",]
CO2[CO2$uptake>mean(CO2$uptake) & CO2$conc>200,]

unique(dataframeA): Remove DUPLICATE rows

scale(x, center=TRUE, scale=TRUE): centers & scales the data (deducts the mean per column, divides by standard deviation)

```

Let's filter the data to exclude respondents who look < 2 mins to complete the survey.

```{r}


```



# Interactive Graphs using Plotly

- Try example in _.Rmd_ file
```{r warning = FALSE, message = FALSE, eval = FALSE}
library(shiny)
library(plotly)

data(diamonds, package = "ggplot2")
nms <- names(diamonds)

ui <- fluidPage(

    headerPanel("Diamonds Explorer"),
    sidebarPanel(
        sliderInput('sampleSize', 'Sample Size', min = 1, max = nrow(diamonds),
                                value = 1000, step = 500, round = 0),
        selectInput('x', 'X', choices = nms, selected = "carat"),
        selectInput('y', 'Y', choices = nms, selected = "price"),
        selectInput('color', 'Color', choices = nms, selected = "clarity"),

        selectInput('facet_row', 'Facet Row', c(None = '.', nms), selected = "clarity"),
        selectInput('facet_col', 'Facet Column', c(None = '.', nms)),
        sliderInput('plotHeight', 'Height of plot (in pixels)', 
                    min = 100, max = 2000, value = 1000)
    ),
    mainPanel(
      plotlyOutput('trendPlot', height = "900px")
    )
)

server <- function(input, output) {

  #add reactive data information. Dataset = built in diamonds data
  dataset <- reactive({
    diamonds[sample(nrow(diamonds), input$sampleSize),]
  })

  output$trendPlot <- renderPlotly({

    # build graph with ggplot syntax
    p <- ggplot(dataset(), aes_string(x = input$x, y = input$y, color = input$color)) + 
      geom_point()

    # if at least one facet column/row is specified, add it
    facets <- paste(input$facet_row, '~', input$facet_col)
    if (facets != '. ~ .') p <- p + facet_grid(facets)

    ggplotly(p) %>% 
      layout(height = input$plotHeight, autosize=TRUE)

  })

}

shinyApp(ui, server)
```

